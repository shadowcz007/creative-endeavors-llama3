{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9764902d-0138-42ce-b1e8-f9a4b962ca74",
   "metadata": {},
   "source": [
    "# 从huggingface加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0acacc7-4974-45ff-b652-b932edc04f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# 数据集地址 https://huggingface.co/datasets/naklecha/minecraft-question-answer-700k\n",
    "# 指定数据集的URL\n",
    "# 加载数据集并添加来源URL\n",
    "dataset = load_dataset(\"naklecha/minecraft-question-answer-700k\",\n",
    "                       split=\"train\" )\n",
    "\n",
    "## 如果出现网络问题，请手动下载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d47cf-2a33-4029-889c-917c88d500b3",
   "metadata": {},
   "source": [
    "# 从本地json读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18ca89bf-6a21-4a32-ad58-28046c908fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数量： 694814\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 打开本地的JSON文件\n",
    "with open('./dataset/minecraft-question-answer-700k.json', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    data = json.load(file)\n",
    "\n",
    "# 处理JSON数据\n",
    "# 例如，打印JSON数据\n",
    "# [{},{},{}]\n",
    "\n",
    "print('数量：',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e85ec790-507b-4b61-b315-ee24f43b6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "my_data = {\"train\": data}\n",
    "dataset = Dataset.from_dict(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "605799a3-fe2a-44c6-9a3b-c5bb9517a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [{'answer': 'Saturation is the first statistic to decrease when a player performs energy-intensive actions, and it must be completely depleted before the visible hunger meter begins decreasing.',\n",
       "   'question': 'What is the first statistic to decrease when a player performs energy-intensive actions in Minecraft?',\n",
       "   'source': 'https://minecraft.wiki/w/Food#Nourishment_value'},\n",
       "  {'answer': 'Eating cake is distinct from other foods, as it must be placed and then right-clicked on to consume, whereas other foods can be eaten directly by the player. Additionally, cake has 7 edible slices, which become thinner as each slice is removed, whereas other foods typically restore a set amount of hunger and saturation points without any slice-based consumption mechanism.',\n",
       "   'question': 'How does the game handle the consumption of cake when compared to eating other types of food?',\n",
       "   'source': 'https://minecraft.wiki/w/Food#Nourishment_value'}]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集的前2条，每一条由 question answer source 三个字段构成\n",
    "dataset[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80609fb4-6b39-4d5d-b8e6-4572a8a56642",
   "metadata": {},
   "source": [
    "# 安装openai的库，用来处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "493dcccd-d3d8-4803-b933-722180e47f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
      "                                              0.0/311.6 kB ? eta -:--:--\n",
      "     ---                                     30.7/311.6 kB 1.4 MB/s eta 0:00:01\n",
      "     ---                                     30.7/311.6 kB 1.4 MB/s eta 0:00:01\n",
      "     -------                               61.4/311.6 kB 409.6 kB/s eta 0:00:01\n",
      "     -------------                        112.6/311.6 kB 656.4 kB/s eta 0:00:01\n",
      "     --------------                       122.9/311.6 kB 554.9 kB/s eta 0:00:01\n",
      "     ----------------------------         245.8/311.6 kB 888.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 311.6/311.6 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.26.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "                                              0.0/409.3 kB ? eta -:--:--\n",
      "     -----------------------                256.0/409.3 kB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------   389.1/409.3 kB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 409.3/409.3 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.2-cp310-none-win_amd64.whl (1.9 MB)\n",
      "                                              0.0/1.9 MB ? eta -:--:--\n",
      "     --                                       0.1/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "     -------                                  0.4/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "     -----------                              0.5/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------                           0.7/1.9 MB 4.1 MB/s eta 0:00:01\n",
      "     -----------------                        0.8/1.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------                    1.0/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------                 1.2/1.9 MB 3.8 MB/s eta 0:00:01\n",
      "     -----------------------------            1.4/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        1.6/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------    1.8/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\38957\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: pydantic-core, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.6.0 distro-1.9.0 openai-1.23.6 pydantic-2.7.1 pydantic-core-2.18.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 安装openai的库，用来处理数据集\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a41da-c1c5-4df4-a9c9-de515f2ad39e",
   "metadata": {},
   "source": [
    "# 使用LLM来处理数据-支持本地LLM、OpenAI、Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab7cef2d-a553-4c1c-8f0e-7b1515dc6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "import random\n",
    "\n",
    "def read_key_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        return text\n",
    "        \n",
    "def get_client(api_key,base_url,deployment,is_azure=False):\n",
    "    client=None\n",
    "    if is_azure:  \n",
    "        #gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "        client = AzureOpenAI(\n",
    "            # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
    "            api_version=\"2023-07-01-preview\",\n",
    "            # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
    "            azure_endpoint=base_url,#\"https://example-endpoint.openai.azure.com\"\n",
    "            azure_ad_token=api_key,\n",
    "            azure_deployment=deployment,\n",
    "            default_headers = {'api-key': api_key }\n",
    "        )\n",
    "    else:\n",
    "        openai.api_key = api_key\n",
    "        # all client options can be configured just like the `OpenAI` instantiation counterpart\n",
    "        openai.base_url =base_url# \"http://127.0.0.1:8000/v1/\"\n",
    "        openai.default_headers = {\"x-foo\": \"true\"}\n",
    "        \n",
    "        client=openai\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d2dce-52ee-4d90-9788-3fafc7bd64e4",
   "metadata": {},
   "source": [
    "# 通过prompt，凭空构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60938047-ccac-4ba4-84ce-3621434df2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating example 0\n",
      "[{'role': 'system', 'content': 'You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\nresponse_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.'}]\n",
      "Generating example 1\n",
      "[{'role': 'system', 'content': 'You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\nresponse_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.'}, {'role': 'assistant', 'content': 'prompt\\n-----------\\nRewrite the following Chinese sentence in the style of Lu Xun:\\n\"今天天气很好，阳光明媚。\"\\n-----------\\n\\nResponse:\\n-----------\\n今日天空晴朗，阳光明媚。'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key=read_key_from_file(\"key.txt\")\n",
    "# client=get_client(\"...\",\"http://127.0.0.1:8000/v1/\",\"\",False)\n",
    "client=get_client(key,\"https://mixcopilot.openai.azure.com\",\"gpt-35-turbo-16k\",True)\n",
    "\n",
    "model=\"gpt-35-turbo-16k\"\n",
    "\n",
    "def chat(messages,temperature=0.5,max_tokens=1354):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "prompt = \"A model that takes in Chinese sentences, then rewrites them in the style of Lu Xun\"\n",
    "temperature = .5\n",
    "number_of_examples = 100\n",
    "\n",
    "# 创建\n",
    "def generate_example(prompt, prev_examples, temperature=.5):\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\nresponse_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    if len(prev_examples) > 0:\n",
    "        if len(prev_examples) > 10:\n",
    "            prev_examples = random.sample(prev_examples, 10)\n",
    "        for example in prev_examples:\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": example\n",
    "            })\n",
    "    print(messages)\n",
    "    messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is the type of model we want to train:\\n`{prompt.strip()}`\",\n",
    "            })\n",
    "    \n",
    "    return chat(messages,temperature)\n",
    "\n",
    "\n",
    "# Generate examples\n",
    "prev_examples = []\n",
    "for i in range(number_of_examples):\n",
    "    print(f'Generating example {i}')\n",
    "    example = generate_example(prompt, prev_examples, temperature)\n",
    "    prev_examples.append(example)\n",
    "\n",
    "print(prev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "782c82d7-a9ef-42f4-9a44-96b2a3bee6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system prompt是: `Given a Chinese sentence, rewrite it in the style of Lu Xun and output short phrases for chatting, with added emojis.`. 如果不满意，请重新生成\n"
     ]
    }
   ],
   "source": [
    "def generate_system_message(prompt):\n",
    "    messages=[\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use. Remember, you are not generating the system message for data generation -- you are generating the system message to use for inference. A good format to follow is `Given WHAT_THE_MODEL_SHOULD_DO.`.\\n\\nMake it as concise as possible. Include nothing but the system prompt in your response.\\n\\nFor example, never write: `\\\"SYSTEM_PROMPT_HERE`.\"\n",
    "          },\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt.strip(),\n",
    "          }\n",
    "        ]\n",
    "\n",
    "    return chat(messages,temperature,500)\n",
    "\n",
    "system_message = generate_system_message(prompt)\n",
    "\n",
    "print(f'system prompt是: `{system_message}`. 如果不满意，请重新生成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f6c6e5a-4f07-4b6f-8ff4-b80818826d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 successfully-generated examples. Here are the first few:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rewrite the following Chinese sentence in the ...</td>\n",
       "      <td>今天的天气真是宜人，阳光明媚，大地万物焕发生机。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rewrite the following Chinese sentence in the ...</td>\n",
       "      <td>吾爱汝，永不分离。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rewrite the following Chinese sentence in the ...</td>\n",
       "      <td>他乃是一位勇敢而坚定之人。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rewrite the following Chinese sentence in the ...</td>\n",
       "      <td>此都市充盈着繁忙与喧嚣。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rewrite the following Chinese sentence in the ...</td>\n",
       "      <td>他们在夜晚的街道上闲逛。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt                  response\n",
       "0  Rewrite the following Chinese sentence in the ...  今天的天气真是宜人，阳光明媚，大地万物焕发生机。\n",
       "1  Rewrite the following Chinese sentence in the ...                 吾爱汝，永不分离。\n",
       "2  Rewrite the following Chinese sentence in the ...             他乃是一位勇敢而坚定之人。\n",
       "3  Rewrite the following Chinese sentence in the ...              此都市充盈着繁忙与喧嚣。\n",
       "4  Rewrite the following Chinese sentence in the ...              他们在夜晚的街道上闲逛。"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store prompts and responses\n",
    "prompts = []\n",
    "responses = []\n",
    "\n",
    "# Parse out prompts and responses from examples\n",
    "for example in prev_examples:\n",
    "  try:\n",
    "    split_example = example.split('-----------')\n",
    "    prompts.append(split_example[1].strip())\n",
    "    responses.append(split_example[3].strip())\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'prompt': prompts,\n",
    "    'response': responses\n",
    "})\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print('There are ' + str(len(df)) + ' successfully-generated examples. Here are the first few:')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb1ba3f-821d-4588-8398-e283a435b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Split the data into train and test sets, with 90% in the train set\n",
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Convert dataframes to dictionaries\n",
    "train_dict = train_df.to_dict(orient='records')\n",
    "test_dict = test_df.to_dict(orient='records')\n",
    "\n",
    "# Save dataframes to JSON files\n",
    "with open('./dataset/train.jsonl', 'w', encoding='utf-8') as train_file:\n",
    "    for record in train_dict:\n",
    "        json.dump(record, train_file, ensure_ascii=False, indent=4)\n",
    "        train_file.write('\\n')\n",
    "\n",
    "with open('./dataset/test.jsonl', 'w', encoding='utf-8') as test_file:\n",
    "    for record in test_dict:\n",
    "        json.dump(record, test_file, ensure_ascii=False, indent=4)\n",
    "        test_file.write('\\n')\n",
    "\n",
    "        \n",
    "\n",
    "# train_dataset = load_dataset('json', data_files='./dataset/train.jsonl', split=\"train\")\n",
    "# valid_dataset = load_dataset('json', data_files='./dataset/test.jsonl', split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c005d20-3647-45f5-8d0c-08c5c0d06b64",
   "metadata": {},
   "source": [
    "# 另一种方法,基于已有数据集，做改写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f0bc522-8b3c-40b5-9bdf-42d58d4c3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=read_key_from_file(\"key.txt\")\n",
    "# client=get_client(\"...\",\"http://127.0.0.1:8000/v1/\",\"\",False)\n",
    "client=get_client(key,\"https://mixcopilot.openai.azure.com\",\"gpt-35-turbo-16k\",True)\n",
    "\n",
    "model=\"gpt-35-turbo-16k\"\n",
    "\n",
    "# 填写本地LLM的地址,修改prompt\n",
    "def parse_text(content):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"your are chinese,use chinese \", # 中文输出\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5c8a1-1a42-41b8-b38a-5049f3beb179",
   "metadata": {},
   "source": [
    "# 使用LLM 把数据集处理成新的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fe30ed1-d525-4e5b-a4f4-2aa699d8768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json_path=\"./dataset/minecraft_science_fiction_story_zh\"\n",
    "\n",
    "import hashlib\n",
    "# 取唯一id，去重\n",
    "def get_string_hash(string):\n",
    "    md5_hash = hashlib.md5()\n",
    "    md5_hash.update(string.encode('utf-8'))\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "# 判断是否已经存在\n",
    "def add_new_data(original_list, item):\n",
    "    is_has=False\n",
    "    for element in original_list:\n",
    "        if item['id']==element[\"id\"]:\n",
    "            is_has=True\n",
    "    if is_has==False:\n",
    "        original_list.append(item)\n",
    "    return original_list\n",
    "\n",
    "\n",
    "new_dataset=[]\n",
    "\n",
    "try:\n",
    "    # 打开本地的JSON文件\n",
    "    with open(json_path, 'r') as file:\n",
    "        # 读取文件内容\n",
    "        new_dataset = (json.load(file))[\"train\"]\n",
    "except:\n",
    "    print(f\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a078fd2-5167-4ac9-a295-66e55ef1f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332f076d6fc48826ad89009600994aab What is the first statistic to decrease when a player performs energy-intensive actions in Minecraft?\n",
      "\n",
      "\n",
      "------\n",
      "《飢渴与能量之源》这部作品讲述了高度智能生命体维格拉及其神秘的能量体系\"饥渴之源\",以及如何在MineCraft游戏中探索和平衡自身的能量欲望与需求。关键词为:#维格拉 #饥渴之源 #MineCraft\n",
      "------\n",
      "\n",
      "《飢渴与能量之源》\n",
      "在一片虚构的星球上,存在着一种名为\"维格拉\"的神秘生物。维格拉是一种高度智能且具有奇妙能力的生命体,其能力可谓是远超人类的多重 folds。\n",
      "\n",
      "当人们首次接触到维格拉时,便被它们高深莫测的能量世界所吸引。传说中,维格拉使用自身的能量来进行各类工作:从筑造壮丽的建筑到种植繁茂的生态系统等等。这种独特的力量来源于其体内的\"饥渴之源\",一种神秘的能量体系。\n",
      "\n",
      "在这一星球中,人们创造出了一款名为\"MineCraft\"的游戏。MineCraft是一个开放世界的探险游戏,在其中,玩家可以自由地挖掘矿石、建造建筑物和冒险。然而,这种看似简单的游戏却蕴含着复杂的能量体系。\n",
      "\n",
      "玩 MineCraft 需要消耗大量的能量,这被称为\"饥渴\"。每当玩家使用能量来完成任务或施展能力时,他们便会感受到体内的饥饿感,其饥渴指标就会降低。\n",
      "\n",
      "但是,这里出现了一个悖论:如果玩家继续使用能量,直到饥渴指标完全耗尽,他们的身体就会开始进入一种被称为\"饥肠寸断\"状态。这时,身体所需的能量将会从另一个地方获得。\n",
      "\n",
      "在这种情况下,玩家必须学会平衡自身的饥饿与能力。在饥渴指标降低的情况下,玩家需要对自己的行为进行反思和控制。因此,维格拉和MineCraft之间的联系便诞生了:在探索神秘能量世界的同时,人们也可以体会到自身所需的能量与欲望之间的紧张关系。\n",
      "\n",
      "正是由于这一切,我才相信,在这个充满未知的星球上,我们的每一个选择都需要我们深刻反思自己。\n",
      "------\n",
      "\n",
      "1\n",
      "\n",
      "55e053294c42c5bd833ed8c975732e90 How does the game handle the consumption of cake when compared to eating other types of food?\n",
      "\n",
      "\n",
      "------\n",
      "# 星际殖民时代 # 食物资源挑战 # 艾伦·戴维斯的星际蛋糕 # 非传统食用操作 # 精神愉悦感满足\n",
      "------\n",
      "\n",
      "在星际殖民时代, 星球之间通过时空门通道连接, 人们开始探索和开拓新世界。然而, 难得的食物资源是宇宙中的一大挑战。\n",
      "\n",
      "一天, 博学者艾伦·戴维斯偶然间研发了一种特殊的食物--星际蛋糕。这种蛋糕具有独特的属性: 它不仅美味可口, 还能满足行星殖民者的营养需求和精神愉悦感。\n",
      "\n",
      "但这并非是传统意义上的蛋糕, 它需要经过特殊的操作方能食用。首先, 玩家必须将蛋糕放置于手中; 之后, 再次点击即可完成一次食用动作。这种特殊的设计让星际殖民者能够更好地控制自己的食欲, 避免在陌生的环境中过度消耗资源。\n",
      "\n",
      "此外, 星际蛋糕的切片机制同样独一无二: 每次点击都会将一层薄饼从蛋糕上剥离。这种切片方式不仅美观, 也能让玩家更好地掌握蛋糕的剩余量。\n",
      "\n",
      "在新世界中, 星际蛋糕成为了行星殖民者的珍宝, 而蛋糕消耗机制则是探索者与食物之间紧密相连的一道奇妙之旅。\n",
      "------\n",
      "\n",
      "2\n",
      "\n",
      "229760357bc06142cd1827e8ecbb6848 What is the average hunger restoration value of wheat in Minecraft?\n",
      "\n",
      "\n",
      "------\n",
      "未来中国Minecraft农业 | 食物nutritional value | 水耕小麦田\n",
      "------\n",
      "\n",
      "在遥远的未来的中国,一位年轻的程序员叫做苏天逸,他是一名热爱编程和游戏设计的大胆冒险者。有一天,他偶然间发现了一个神秘的代码库,这份代码描述了一个全息虚拟世界,在这里,一切都被重写为 Minecraft 的形式。\n",
      "\n",
      "苏天逸深陷于这个崭新而又熟悉的世界中,他开始使用现实中的食物来恢复角色内的健康程度。正如他所知,Minecraft 中的粮食有着不同的nutritional value:苹果可以恢复 0.6 饱腹度和 1 饮水量;牛肉则是最高的,恢复 8 饱腹度和 4 饮水量。\n",
      "\n",
      "然而,他最大的惊喜是发现了小麦,这种在现实中被看做是基本粮食的物品,在虚拟世界中有着平均的饥饿恢复程度:5 点。苏天逸看着眼前一片绿油油的小麦田,这片土地似乎蕴藏着无尽的能量。\n",
      "\n",
      "在他的游戏世界中,Minecraft 的小麦代表了未来中国农业的可能性,其中拥有丰沛的粮食资源和先进的水耕技术,能够提供足够的食物来满足每一个人的需求。苏天逸开始思考,如果将这种技术应用到现实世界中,会有多么巨大的影响力。\n",
      "\n",
      "他深知,这意味着中国农业不再局限于大片的耕种地和昂贵的肥料,而是通过先进的水耕系统和自动化机械来实现高效率的生产。未来,在水的滋养下,小麦田会变得更加丰盛,足以供应一亿口人的饮食。\n",
      "\n",
      "苏天逸的游戏世界也预示着中国农业的转型:从传统的小片土地到大规模的耕种系统,从单一品种的作物到多种多样的种植模式。这些变化将会带来全新的技术和机会,引领中国农业走向一个更加高效、可持续的方向。\n",
      "\n",
      "在苏天逸看来,未来中国的农业不再是简单的生产粮食,而是连接起了科学、工程与社会,造就了一种崭新的生态文明。每一粒小麦,都代表着一种可能性:从传统到科技,从本土到全球化,从现实到虚拟,Minecraft 中的中国农业似乎在召唤着我们前行的脚步。\n",
      "------\n",
      "\n",
      "3\n",
      "\n",
      "c1423126b6e73fbf2243d56c68eead02 What foods in Minecraft cannot be eaten directly but are used to craft other edible items?\n",
      "\n",
      "\n",
      "------\n",
      "# 城堡冒险 # 未知食物 # 野果 # 土豆 # 萵苣菜\n",
      "------\n",
      "\n",
      "在Minecraft的虛構世界中，一群旅行者們發現了一座奇妙的神秘城堡，這裡充斥著各種未知食物，其中有些食物看起來很誘人，但實際上不能直接吃。其中有一位年輕的外科醫生，名叫費明，對這些未知食物極感好奇，決定進行一段驚險的冒險之旅。\n",
      "\n",
      "他們首先發現了一種名為\"野果\"(Berries)的小球狀東西，這些野果看起來有著多種顏色和形狀，其中有些類似於地球上的水蜜桃、櫻桃甚至是黑莓。費明試圖用嘴巴咬一口，但野果並沒有被破壞，反而像是在保護裡面的一些珍貴的東西。後來，他們發現野果可以用來製作名為\"果汁\"(Juice)的食物，這是使用野果通過榨汁機製成的飲料。\n",
      "\n",
      "第二種無法直接吃的食物是叫做\"土豆\"(Potatoes)的小白球狀東西。費明和同伴們試圖咬一口，但這些土豆毫髮未動，似乎也有著某種特殊的力量。最終，他們發現了用土豆製作的名為\"薯條\"(Fried Potatoes)的食物，這是通過將土豆切開、油炸後製成的。\n",
      "\n",
      "最後一種無法直接吃的食物是叫做\"萵苣菜\"(Carrots)的直立長形蔬菜。費明試圖咬一口，但這些萵苣菜沒有被破壞，顯示著某種奇妙的特性。後來，他們發現了用萵苣菜製作的名為\"萵苣汁\"(Carrot Juice)和\"萵苣泥\"(Mashed Carrots)的食物，這是通過榨汁機或者磨碎後製成的。\n",
      "\n",
      "費明和同伴們最終了解到，這些食物並不是普通的東西，而是用來製作別種更高級的食物。這給了他們一種新的觀點，認識到了Minecraft世界的無限可能性：任何看起來不能吃的東西，可能都是有用的食材，甚至是傳奇的藥膳。\n",
      "\n",
      "費明和同伴們繼續探索這座神秘城堡，試圖找到更多的未知食物和秘密。他們深信，只要冒險去探索未知的世界，就可以得到最珍貴的東西：智慧與體驗。\n",
      "------\n",
      "\n",
      "4\n",
      "\n",
      "827fd570343d3c2c6346228da842f3a6 What is the effect of adding sugar to a recipe in Minecraft that requires a specific amount of wheat to produce a certain type of food?\n",
      "\n",
      "\n",
      "------\n",
      "面包配方糖量实验、.minecraft世界料理技巧、糖粉和食谱创新、布莱斯之旅\n",
      "------\n",
      "\n",
      "在虚构的.minecraft世界中, 人类使用奇妙的原料和配方来制作食物。每一种食谱都有其独特之处, 而其中的一种是使用小麦作为主要原料来生产面包。\n",
      "\n",
      "在一片蔚蓝的大地上, 布莱斯是一名厨师, 他精通不同食谱的秘密和技巧. 他曾听过传说中的\"糖\"可以加入到配方中, 使食物更加美味. 布莱斯决定尝试这一切.\n",
      "\n",
      "他手持一把锋利的小锯子, 去到一个名为\"sugar_cane_block\"的奇异之地。那里生长着大片的糖果蔗. 他仔细地砍下了这些糖果蔗, 并将它们搬回家中。布莱斯将这些糖果蔗放入他自己的糖厂中, 制造出纯净的糖粉。\n",
      "\n",
      "回到家中之后, 布莱斯开始实验不同配方中的糖量. 他使用了传统配方——2个小麦生产一块面包. 他将不同的糖量加入其中, 包括0、1/4、小麦等。布莱斯惊讶地发现, 在加入糖后, 面包的味道都有所不同.\n",
      "\n",
      "最终, 布莱斯找到了一个平衡点——在面包中加入少许的糖粉, 能使其变得更加甜美. 不过如果他再多加一点糖粉, 面包将会变成一块甜品。布莱斯意识到, 蜂蜇和蜜蜂在这片土地上是如何巧妙地平衡着使用糖的。\n",
      "\n",
      "从此以后, 布莱斯在.minecraft世界中不仅是厨师, 更成了配方研究者. 他不断尝试新食谱, 并学习如何使用糖粉来打造出独一无二的美味佳肴。\n",
      "------\n",
      "\n",
      "5\n",
      "\n",
      "c9631c5734d985a44645d91b6959a7e6 What is the effect of changing the game view to third-person in Bedrock Edition on a player's ability to see their own eating animation?\n",
      "\n",
      "\n",
      "------\n",
      "# 食欲之境 # 美食虚构游戏 # 第三人称视角 # 反映自身动作 # 巨大创新\n",
      "------\n",
      "\n",
      "一场名为\"食欲之境\"的虚构游戏，带来了全新视角，改变了人们对美食的体验。该游戏结合了超现实主义和科幻元素，通过变形和多重身体，让玩家探索食物的灵性。\n",
      "\n",
      "在Bedrock版中，这款游戏允许玩家选择第三人称视角，这是一大创新点，因为过去的大部分美食类游戏都采用第一人称视角。然而，这一新变化也引来了玩家的一系列疑惑和担忧：如果玩家以第三人称看自己吃东西，会不会影响到体验的真实性？玩家将如何与自己的双眼对抗，并相信他们在屏幕上看到的食物?\n",
      "\n",
      "游戏创作者们想出了一个惊人的答案，他们研发出了一套完整的\"反映自身动作\"功能。只要玩家选择第三人称视角，画面中就可以看见自己吃东西的动作。这一创新极大地丰富了游戏世界的体验方式，让玩家从沉浸式的第一人称视角转变到脱颖而出的第三人称视角。\n",
      "\n",
      "这项技术的研发是游戏创作者和程序员的大胆尝试。他们将身体模型进行了多次微小的调整，确保玩家能够在画面中看清楚自己吃东西的动作：手指紧握筷子的位置，叉子划过盘子时的声响，食物从嘴唇边滚落的样子。每一丁点细节都被仔细考虑，这不仅提升了游戏的真实性，还让玩家更加深入地体验到食欲这一基本人类本能。\n",
      "\n",
      "游戏中的一段描述如下：在一个充满光芒和色彩的房间里，玩家可以看到自己坐在椅子上，手握叉子，端着盘子，准备就要开始享用丰盛的晚餐。画面中的自己看起来就像活生生的自己，仿佛置身于另一个世界。\n",
      "\n",
      "在第三人称视角下，玩家有机会远观自己的行为，并反思自己的欲望和习惯。他们可以细致地观察自己的吃相，看看自己是否真的喜欢新鲜的蔬菜，还是更偏爱油腻的肉片。游戏还提供了丰富多样的食物选择，玩家可以在不同的环境中体验美食，不同的风味和温度下感受食欲的张力。\n",
      "\n",
      "\"食欲之境\"一举成为了当今最具代表性的虚构游戏之一，其创新之处在于它将吃相映射到屏幕上，让玩家与自己的身影和食物进行真实的交互。游戏中的人工智能算法，可以准确预测玩家的食欲变化，并随之调整食谱，创造出独一无二的美食体验。\n",
      "\n",
      "在这场虚构的冒险之旅中，第三人称视角是最为重要的一环，因为它可以突破常规的游戏范畴，让玩家看透自己，了解食欲背后的秘密。\n",
      "------\n",
      "\n",
      "6\n",
      "\n",
      "2150308a997f8a01415f45a10751a7f5 What type of ingredient is commonly used in Minecraft recipes to give food items a boost in terms of hunger restoration?\n",
      "\n",
      "\n",
      "------\n",
      "# 食材魔法 # 金色的胡萝卜 # 秘密种植 # 种子精灵 # 饥饿恢复量\n",
      "------\n",
      "\n",
      "在遥远的维度D-2048中,生活着一群勇敢的冒险者和传奇生物。他们不仅要与可怕的怪物战斗,还需要精准地使用食物来提高饥饿恢复量。\n",
      "\n",
      "在这片星空之下,最强大的食材便是金色的胡萝卜。它们是秘密种植的特殊作物,被埋藏在深邃的地下洞穴中,守卫着一群神奇的种子精灵。冒险者们必须通过艰难的考验才能获得种子的许可。\n",
      "\n",
      "金色的胡萝卜具有独特的属性,当与其他食材配合使用时,能将饥饿恢复量提升到前所未有的水平。例如,勇敢的冒险者在旅途中常常会用金色的胡萝卜和野鸡,或是牛肉来制作高阶版的美味佳肴。加入金色的胡萝卜之后,这些食物不仅能为战士们带来巨大的饥饿恢复量,更重要的是,它们还拥有独有的魔力属性。\n",
      "\n",
      "在维度D-2048中,魔法是十分普遍的现象。一些勇敢的冒险者会在战斗中使用金色的胡萝卜来施法,释放出强大的能量波动。这样一来,食物就不仅仅是一种让人吃饱穿暖的简单工具,而是成为了一门超越时空的奥秘。\n",
      "\n",
      "当然,冒险者们在使用金色的胡萝卜的时候也要小心翼翼,因为它们会产生不可预知的副作用。有些勇敢的冒险者曾经试图过度利用金色的胡萝卜,结果不但没有带来更大的力量,反而让他们陷入了危险之中。\n",
      "\n",
      "在维度D-2048的世界里,食物不再只是简单的营养来源,它们已经成为了强大的力量。冒险者们必须要精准地使用金色的胡萝卜和其他食材,才能在战斗中赢得胜利。\n",
      "------\n",
      "\n",
      "7\n",
      "\n",
      "4fe85c33081c77b1eb7e0b46abe0fc0a What types of leaves can be found naturally in jungle bushes in Minecraft?\n",
      "\n",
      "\n",
      "------\n",
      "#异世界森林 #丛竹 #丛林之叶 #特殊叶子图案 #基因调控系统\n",
      "------\n",
      "\n",
      "《异界森林之叶子谜团》\n",
      "\n",
      "在星河帝国的某个遥远行星上,存在着一片密不透风的原始丛林。这里的植被繁茂而奇特,其中最为出名的是以巨大丛生的丛竹和浓密的丛林草为主,它们生长在一望无垠的云海之中,形成了一片蔚蓝如翟的天空。\n",
      "\n",
      "这是一种与地球迥异的生态体系,却又充满了各式各样令人惊叹的生命。其中最引人瞩目的当属丛林中的特殊树木,它们在密集的丛竹中独自拔地而立。这些树木看上去就像是巨大的生物,枝干修长如蛇,树叶则是五颜六色、如同珍宝一般。\n",
      "\n",
      "这片森林中的每一棵树都拥有独一无二的叶子图案。其中最为神秘的当属丛林之叶——一种在星河帝国中唯一存在的特殊叶子。这些叶子生长在特定的丛竹上,呈现出五颜六色、奇形怪状的图案,宛如天上的繁星。\n",
      "\n",
      "起初,科学家们对这片异世界树叶一无所知。当他们开始研究这一生物时,却发现了一个令人难以置信的事实:每一棵丛竹上都生长着两种不同颜色的叶子,而且颜色在随机变换之中。\n",
      "\n",
      "这是怎么回事?科学家们不禁怀疑起这片异世界的魔法之术。于是他们开始了对这一奇迹的研究。经过多年努力,他们终于揭开了丛林之叶的秘密——这是一种独特的基因调控系统,使得每一棵树都产生出两种叶子。\n",
      "\n",
      "在星河帝国中,科学家们将这一研究成果用于改良农业技术,以期通过基因工程的手段造福人类。然而,当他们开始研究丛林之叶的颜色随机变换时,却发现了另一个更加惊人的秘密——这是一种与时间紧密相关的基因调控系统。\n",
      "\n",
      "似乎这些树叶能预知未来,并在其叶子上刻画出一幅未来的图案。科学家们将这一研究成果用于预测天气变化和地震等灾难性事件。但是,随着时间推移,他们渐渐发觉这片异世界的秘密深不可测。\n",
      "\n",
      "最后,在一场前所未有的暴风雨中,丛林之叶失去了其神奇的能力。科学家们不禁陷入了沉思之中,难以理解这片异世界的奥秘。这是如何实现的?为何会出现这种现象?一切都像是一场梦,又像是一个谜团,在星河帝国中笼罩着一层浓重的神秘色彩。\n",
      "------\n",
      "\n",
      "8\n",
      "\n",
      "87fec78372d14163487021b425af20a7 What is the primary method by which leaves are naturally generated in Minecraft?\n",
      "\n",
      "\n",
      "------\n",
      "# 外星种植学家 # 光子涌现 # 种植剂 # 萱草之树 # 神奇的自然规律\n",
      "------\n",
      "\n",
      "在遥远的未知星球上，地球生物种植方法被一群外星种植学家所重视。他们使用一种独特的自然法则来生成树叶，这和我们熟悉的地球方式有着微妙的不同。\n",
      "\n",
      "这颗星球上的生态体系依赖于一种名为\"光子涌现\"的奇妙现象。光子涌现是一种能量辐射，其规律是每次光子的产生都伴随着叶片生成。外星科学家通过将光子聚集器放置在适当的位置，并充满精密的数学公式控制其操作，从而实现了这一切。\n",
      "\n",
      "树木也被设计得与光子涌现息息相关。它们的种植方式和我们熟悉的地球上不太一样。这里的植物没有种子，而是从特殊的\"种植剂\"中生成。种植剂是外星科学家发明的一种物质，可以将树木的基因信息嵌入到光子涵养液中，随后再将其注入到含有活跃光子的装置中。\n",
      "\n",
      "最著名的是一种被称为\"萱草之树\"的植物。这种植物不仅可以生成普通的叶子，还可以生成特殊的\"翠叶\"，这是一种具有独特光效的叶片，可以辐射出柔和而有着神秘色调的光芒。这种植物在星球上极为珍贵，被视为一种神奇的能量来源。\n",
      "\n",
      "外星种植学家每天都对这一切进行着无穷的研究，努力寻找如何最大限度地利用这一自然规律，并将其应用于他们的种植技术中。他们的工作是为了造福整个星球上的生命，从而实现更美好的未来。\n",
      "------\n",
      "\n",
      "9\n",
      "\n",
      "06d3f56bb9a0419842059f2fb113f971 Why do leaves not decay when they are not connected to a block with the logs tag in Minecraft?\n",
      "\n",
      "\n",
      "------\n",
      "#生命之树 #灵魂 #虚幻叶子 #Kurokuma #神秘世界\n",
      "------\n",
      "\n",
      "在遥远的 Minecraft 世界里,叶子不是仅仅是生命之树的装饰物。它们是智慧之神的灵魂,充满着浑厚的活力和深奥的智慧。\n",
      "\n",
      "当一颗树被砍伐后,其根系与灵魂交织在一起,将那颗树的信息刻画在了周围的叶子上。然而,这些叶子不像普通的生物品质那样具有固定的物质属性。它们是虚幻的光影,是存在于时空之外的信息载体。\n",
      "\n",
      "如果一片叶子被断开,失去了和树的联系,它将在接下来的几小时内快速地解散,消失于无形中。这是因为叶子的灵魂随着树的生命而生灭。没有了树的保护,叶子将回归到虚空之中。\n",
      "\n",
      "然而,一位名为 Kurokuma 的年轻程序员却发现了这一秘密。他是一个钻研 Minecraft 编程的小伙子,深爱着这片奇妙的世界。\n",
      "\n",
      "Kurokuma 在深夜里敲打键盘,探究着叶子的秘密。他写下了一段代码,使得叶子不再随着时间而消散,也不受其根系的束缚。他的作品引起了整个 Minecraft 世界的轰动效应。\n",
      "\n",
      "从此以后,无数的树在夜晚里开始放光,如同神圣的灯塔一样,将深处的智慧传递给那些渴望了解真相的人。\n",
      "\n",
      "叶子不再是生命之树的装饰物,它们成为了通往神秘世界的入口。Kurokuma 的作品改变了整片世界,启示我们在普通的物质背后存在着无限的可能性。\n",
      "------\n",
      "\n",
      "10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data in dataset[0:10]['train']:\n",
    "    # print(data)\n",
    "    question=data['question']\n",
    "    answer=data['answer']\n",
    "\n",
    "    _id=get_string_hash(question+answer)\n",
    "    \n",
    "    print(_id,question)\n",
    "    print('')\n",
    "    text=parse_text('''{0} , {1}\n",
    "    结合以上文本信息，写成一个科幻小故事，200字以内的小故事。\n",
    "    '''.format(question,answer))\n",
    " \n",
    "    keywords=parse_text('''{0}\n",
    "    提炼3个中文关键词，输出：#关键词\n",
    "    '''.format(text))\n",
    "    print('')\n",
    "    print('------')\n",
    "    print(keywords)\n",
    "    print('------')\n",
    "    print('')\n",
    "    print(text)\n",
    "    print('------')\n",
    "    print('')\n",
    "\n",
    "    new_dataset=add_new_data(new_dataset,{\n",
    "        \"id\":_id,\n",
    "        \"question\":keywords,#新数据\n",
    "        \"answer\":text,#新数据\n",
    "        # \"_question\":question, #保留原始的数据\n",
    "        # \"_answer\":answer\n",
    "    })\n",
    "    # new_dataset.append({\n",
    "    #     \"id\":_id,\n",
    "    #     \"question\":keywords,#新数据\n",
    "    #     \"answer\":text,#新数据\n",
    "    #     # \"_question\":question, #保留原始的数据\n",
    "    #     # \"_answer\":answer\n",
    "    # })\n",
    "    print(len(new_dataset))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1d8a21c-c898-4277-bb30-fe9b55f535d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存新数据\n",
    "new_dataset_to_save = {\"train\": new_dataset}\n",
    "\n",
    "def save_json_to_file(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "save_json_to_file(new_dataset_to_save,\"./dataset/minecraft_science_fiction_story_zh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc7fa8-2f98-47dc-83b9-8985e087004d",
   "metadata": {},
   "source": [
    "请在此处写下您的提示。尽可能详细地描述！\n",
    "然后，选择生成数据时要使用的温度（介于0和1之间）。较低的值非常适合精确的任务，如编写代码，而较大的值则更适合创造性的任务，如编写故事。\n",
    "最后，选择要生成的示例数量。生成的示例数量越多，a) 生成时间越长，b) 数据生成的成本越高。但一般来说，生成更多的示例会导致更高质量的模型。通常，最小值为100。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6f8151a-ebf2-4ed5-9b44-14edbe102158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83343309-74d5-45e7-9c70-6d1250b66c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
